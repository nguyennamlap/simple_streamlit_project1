"""
File CSV Compression Script - IN-PLACE COMPRESSION
Tá»± Ä‘á»™ng nÃ©n file CSV lá»›n xuá»‘ng kÃ­ch thÆ°á»›c nhá» hÆ¡n Báº°NG CÃCH THAY THáº¾ FILE Gá»C
"""
import pandas as pd
import numpy as np
import os
import warnings
from pathlib import Path
import psutil
import shutil
from datetime import datetime
warnings.filterwarnings('ignore')

class CSVCompressor:
    def __init__(self, target_size_mb=25):
        """
        Khá»Ÿi táº¡o compressor
        
        Args:
            target_size_mb: KÃ­ch thÆ°á»›c má»¥c tiÃªu (MB)
        """
        self.target_size_mb = target_size_mb
        self.original_size_mb = None
        self.compressed_size_mb = None
        self.compression_ratio = None
        
    def optimize_dtypes(self, df):
        """
        Tá»‘i Æ°u hÃ³a kiá»ƒu dá»¯ liá»‡u Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c
        
        Args:
            df: DataFrame cáº§n tá»‘i Æ°u
            
        Returns:
            DataFrame Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u
        """
        print("ğŸ” Äang tá»‘i Æ°u kiá»ƒu dá»¯ liá»‡u...")
        
        # Sao chÃ©p DataFrame Ä‘á»ƒ khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n dá»¯ liá»‡u gá»‘c
        df_optimized = df.copy()
        
        # Duyá»‡t qua tá»«ng cá»™t
        for col in df_optimized.columns:
            col_type = df_optimized[col].dtype
            
            # Tá»‘i Æ°u kiá»ƒu sá»‘ nguyÃªn
            if col_type in ['int64', 'int32']:
                c_min = df_optimized[col].min()
                c_max = df_optimized[col].max()
                
                # Kiá»ƒm tra xem cÃ³ giÃ¡ trá»‹ NaN khÃ´ng
                has_nan = df_optimized[col].isna().any()
                
                if not has_nan:
                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                        df_optimized[col] = df_optimized[col].astype(np.int8)
                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                        df_optimized[col] = df_optimized[col].astype(np.int16)
                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                        df_optimized[col] = df_optimized[col].astype(np.int32)
                else:
                    # Náº¿u cÃ³ NaN, chuyá»ƒn sang kiá»ƒu float tá»‘i Æ°u
                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                        df_optimized[col] = df_optimized[col].astype(np.float16)
                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                        df_optimized[col] = df_optimized[col].astype(np.float32)
            
            # Tá»‘i Æ°u kiá»ƒu sá»‘ thá»±c
            elif col_type in ['float64', 'float32']:
                c_min = df_optimized[col].min()
                c_max = df_optimized[col].max()
                
                # Giáº£m Ä‘á»™ chÃ­nh xÃ¡c float64 -> float32 -> float16
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df_optimized[col] = df_optimized[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df_optimized[col] = df_optimized[col].astype(np.float32)
            
            # Tá»‘i Æ°u kiá»ƒu object/string
            elif col_type == 'object':
                # Kiá»ƒm tra xem cÃ³ pháº£i lÃ  string khÃ´ng
                if df_optimized[col].apply(lambda x: isinstance(x, str)).all():
                    # Chuyá»ƒn sang kiá»ƒu category náº¿u sá»‘ lÆ°á»£ng unique nhá»
                    num_unique = df_optimized[col].nunique()
                    num_total = len(df_optimized[col])
                    
                    if num_unique / num_total < 0.5:  # Náº¿u Ã­t hÆ¡n 50% unique
                        df_optimized[col] = df_optimized[col].astype('category')
        
        # TÃ­nh toÃ¡n má»©c tiáº¿t kiá»‡m bá»™ nhá»›
        original_memory = df.memory_usage(deep=True).sum() / 1024**2  # MB
        optimized_memory = df_optimized.memory_usage(deep=True).sum() / 1024**2  # MB
        savings = ((original_memory - optimized_memory) / original_memory) * 100
        
        print(f"âœ… Tá»‘i Æ°u hoÃ n táº¥t:")
        print(f"   - TrÆ°á»›c: {original_memory:.2f} MB")
        print(f"   - Sau: {optimized_memory:.2f} MB")
        print(f"   - Tiáº¿t kiá»‡m: {savings:.1f}%")
        
        return df_optimized
    
    def compress_csv_in_place(self, input_path, backup_original=True):
        """
        NÃ©n file CSV NGAY Táº I CHá»– (in-place) báº±ng cÃ¡ch lÆ°u láº¡i dÆ°á»›i dáº¡ng CSV Ä‘Ã£ nÃ©n
        
        Args:
            input_path: ÄÆ°á»ng dáº«n file CSV gá»‘c
            backup_original: CÃ³ táº¡o backup file gá»‘c khÃ´ng
            
        Returns:
            True náº¿u thÃ nh cÃ´ng, False náº¿u tháº¥t báº¡i
        """
        print(f"\nğŸ“ Äang xá»­ lÃ½ file: {input_path}")
        
        # Kiá»ƒm tra file tá»“n táº¡i
        if not os.path.exists(input_path):
            print(f"âŒ File khÃ´ng tá»“n táº¡i: {input_path}")
            return False
        
        # Táº¡o Ä‘Æ°á»ng dáº«n táº¡m thá»i
        temp_path = f"{input_path}.temp_compressed"
        
        # TÃ­nh kÃ­ch thÆ°á»›c file gá»‘c
        self.original_size_mb = os.path.getsize(input_path) / (1024**2)
        print(f"ğŸ“Š KÃ­ch thÆ°á»›c gá»‘c: {self.original_size_mb:.2f} MB")
        
        try:
            # Táº¡o backup náº¿u cáº§n
            if backup_original:
                backup_path = f"{input_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                shutil.copy2(input_path, backup_path)
                print(f"ğŸ’¾ ÄÃ£ táº¡o backup: {backup_path}")
            
            # Äá»c file CSV vá»›i chunksize Ä‘á»ƒ xá»­ lÃ½ file lá»›n
            print("ğŸ“– Äang Ä‘á»c file CSV...")
            chunksize = 100000  # Sá»‘ dÃ²ng má»—i chunk
            chunks = []
            
            for i, chunk in enumerate(pd.read_csv(input_path, chunksize=chunksize)):
                chunks.append(chunk)
                print(f"   ÄÃ£ Ä‘á»c chunk {i+1}: {len(chunk):,} dÃ²ng", end='\r')
            
            print(f"\nâœ… ÄÃ£ Ä‘á»c toÃ n bá»™ file: {sum(len(c) for c in chunks):,} dÃ²ng")
            
            # Káº¿t há»£p táº¥t cáº£ chunks
            df = pd.concat(chunks, ignore_index=True)
            
            # Tá»‘i Æ°u kiá»ƒu dá»¯ liá»‡u
            df_optimized = self.optimize_dtypes(df)
            
            # Náº¿u váº«n quÃ¡ lá»›n, giáº£m Ä‘á»™ chÃ­nh xÃ¡c thÃªm
            estimated_size = df_optimized.memory_usage(deep=True).sum() / (1024**2)
            
            if estimated_size > self.target_size_mb * 1.5:
                print("ğŸ“‰ KÃ­ch thÆ°á»›c váº«n lá»›n, Ä‘ang giáº£m Ä‘á»™ chÃ­nh xÃ¡c thÃªm...")
                # Giáº£m táº¥t cáº£ float64 -> float32
                for col in df_optimized.columns:
                    if df_optimized[col].dtype == 'float64':
                        df_optimized[col] = df_optimized[col].astype('float32')
                    elif df_optimized[col].dtype == 'int64':
                        df_optimized[col] = df_optimized[col].astype('int32')
            
            # LÆ°u thÃ nh CSV Ä‘Ã£ nÃ©n (sá»­ dá»¥ng compression)
            print("ğŸ’¾ Äang lÆ°u file CSV Ä‘Ã£ nÃ©n...")
            
            # LÆ°u vá»›i Ä‘á»‹nh dáº¡ng CSV nÃ©n gzip
            df_optimized.to_csv(
                temp_path,
                index=False,
                compression='gzip'  # NÃ©n gzip cho CSV
            )
            
            # Kiá»ƒm tra kÃ­ch thÆ°á»›c file táº¡m
            temp_size_mb = os.path.getsize(temp_path) / (1024**2)
            print(f"ğŸ“Š KÃ­ch thÆ°á»›c file táº¡m: {temp_size_mb:.2f} MB")
            
            # Náº¿u file táº¡m nhá» hÆ¡n file gá»‘c, thay tháº¿ file gá»‘c
            if temp_size_mb < self.original_size_mb:
                # XÃ³a file gá»‘c
                os.remove(input_path)
                # Äá»•i tÃªn file táº¡m thÃ nh file gá»‘c
                os.rename(temp_path, input_path)
                
                # TÃ­nh kÃ­ch thÆ°á»›c sau khi nÃ©n
                self.compressed_size_mb = os.path.getsize(input_path) / (1024**2)
                self.compression_ratio = (self.original_size_mb - self.compressed_size_mb) / self.original_size_mb * 100
                
                print(f"\nğŸ‰ NÃ©n thÃ nh cÃ´ng NGAY Táº I CHá»–!")
                print(f"ğŸ“Š Káº¿t quáº£:")
                print(f"   - File gá»‘c: {self.original_size_mb:.2f} MB")
                print(f"   - File sau nÃ©n: {self.compressed_size_mb:.2f} MB")
                print(f"   - Tá»· lá»‡ nÃ©n: {self.compression_ratio:.1f}%")
                print(f"   - Vá»‹ trÃ­: {input_path} (Ä‘Ã£ Ä‘Æ°á»£c thay tháº¿)")
                
                # ThÃ´ng tin thÃªm vá» dá»¯ liá»‡u
                print(f"\nğŸ“ˆ ThÃ´ng tin dá»¯ liá»‡u:")
                print(f"   - Sá»‘ dÃ²ng: {len(df_optimized):,}")
                print(f"   - Sá»‘ cá»™t: {len(df_optimized.columns)}")
                
                return True
            else:
                print(f"\nâš ï¸  File táº¡m ({temp_size_mb:.2f} MB) Lá»šN HÆ N file gá»‘c ({self.original_size_mb:.2f} MB)")
                print("   Giá»¯ nguyÃªn file gá»‘c vÃ  xÃ³a file táº¡m...")
                os.remove(temp_path)
                return False
            
        except Exception as e:
            print(f"âŒ Lá»—i khi xá»­ lÃ½ file: {str(e)}")
            # XÃ³a file táº¡m náº¿u cÃ³ lá»—i
            if os.path.exists(temp_path):
                os.remove(temp_path)
            return False
    
    def compress_csv_to_parquet_replace(self, input_path, backup_original=True):
        """
        NÃ©n file CSV vÃ  thay tháº¿ báº±ng file Parquet cÃ¹ng tÃªn (Ä‘á»•i Ä‘uÃ´i .csv -> .parquet)
        
        Args:
            input_path: ÄÆ°á»ng dáº«n file CSV gá»‘c
            backup_original: CÃ³ táº¡o backup file gá»‘c khÃ´ng
            
        Returns:
            ÄÆ°á»ng dáº«n file Parquet má»›i
        """
        print(f"\nğŸ“ Äang xá»­ lÃ½ file: {input_path}")
        
        # Kiá»ƒm tra file tá»“n táº¡i
        if not os.path.exists(input_path):
            print(f"âŒ File khÃ´ng tá»“n táº¡i: {input_path}")
            return None
        
        # Táº¡o Ä‘Æ°á»ng dáº«n file Parquet (Ä‘á»•i Ä‘uÃ´i .csv -> .parquet)
        parquet_path = str(Path(input_path).with_suffix('.parquet'))
        
        # TÃ­nh kÃ­ch thÆ°á»›c file gá»‘c
        self.original_size_mb = os.path.getsize(input_path) / (1024**2)
        print(f"ğŸ“Š KÃ­ch thÆ°á»›c CSV gá»‘c: {self.original_size_mb:.2f} MB")
        
        try:
            # Táº¡o backup náº¿u cáº§n
            if backup_original:
                backup_path = f"{input_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                shutil.copy2(input_path, backup_path)
                print(f"ğŸ’¾ ÄÃ£ táº¡o backup CSV: {backup_path}")
            
            # Äá»c file CSV vá»›i chunksize
            print("ğŸ“– Äang Ä‘á»c file CSV...")
            chunksize = 100000
            chunks = []
            
            for i, chunk in enumerate(pd.read_csv(input_path, chunksize=chunksize)):
                chunks.append(chunk)
                print(f"   ÄÃ£ Ä‘á»c chunk {i+1}: {len(chunk):,} dÃ²ng", end='\r')
            
            print(f"\nâœ… ÄÃ£ Ä‘á»c toÃ n bá»™ file: {sum(len(c) for c in chunks):,} dÃ²ng")
            
            # Káº¿t há»£p táº¥t cáº£ chunks
            df = pd.concat(chunks, ignore_index=True)
            
            # Tá»‘i Æ°u kiá»ƒu dá»¯ liá»‡u
            df_optimized = self.optimize_dtypes(df)
            
            # LÆ°u thÃ nh Parquet
            print("ğŸ’¾ Äang lÆ°u file Parquet...")
            df_optimized.to_parquet(
                parquet_path,
                engine='pyarrow',
                compression='gzip',
                index=False
            )
            
            # TÃ­nh kÃ­ch thÆ°á»›c file Parquet
            self.compressed_size_mb = os.path.getsize(parquet_path) / (1024**2)
            self.compression_ratio = (self.original_size_mb - self.compressed_size_mb) / self.original_size_mb * 100
            
            # XÃ³a file CSV gá»‘c (sau khi Ä‘Ã£ lÆ°u Parquet thÃ nh cÃ´ng)
            os.remove(input_path)
            
            print(f"\nğŸ‰ ÄÃ£ thay tháº¿ CSV báº±ng Parquet!")
            print(f"ğŸ“Š Káº¿t quáº£:")
            print(f"   - CSV gá»‘c: {self.original_size_mb:.2f} MB")
            print(f"   - Parquet má»›i: {self.compressed_size_mb:.2f} MB")
            print(f"   - Tá»· lá»‡ nÃ©n: {self.compression_ratio:.1f}%")
            print(f"   - File CSV Ä‘Ã£ Ä‘Æ°á»£c xÃ³a")
            print(f"   - File Parquet má»›i: {parquet_path}")
            
            return parquet_path
            
        except Exception as e:
            print(f"âŒ Lá»—i khi xá»­ lÃ½ file: {str(e)}")
            return None
    
    def compress_multiple_files_in_place(self, file_paths, method='csv_compressed', backup_original=True):
        """
        NÃ©n nhiá»u file CSV NGAY Táº I CHá»–
        
        Args:
            file_paths: Danh sÃ¡ch Ä‘Æ°á»ng dáº«n file
            method: 'csv_compressed' (giá»¯ CSV) hoáº·c 'parquet_replace' (Ä‘á»•i sang Parquet)
            backup_original: CÃ³ táº¡o backup file gá»‘c khÃ´ng
            
        Returns:
            Danh sÃ¡ch káº¿t quáº£
        """
        print(f"ğŸš€ Báº¯t Ä‘áº§u nÃ©n {len(file_paths)} file NGAY Táº I CHá»–...")
        print(f"ğŸ“ PhÆ°Æ¡ng phÃ¡p: {method}")
        print("="*50)
        
        results = []
        
        for i, file_path in enumerate(file_paths, 1):
            print(f"\nğŸ“¦ File {i}/{len(file_paths)}: {Path(file_path).name}")
            
            if method == 'csv_compressed':
                success = self.compress_csv_in_place(file_path, backup_original)
                if success:
                    results.append({
                        'file': file_path,
                        'status': 'success',
                        'original_size_mb': self.original_size_mb,
                        'compressed_size_mb': self.compressed_size_mb,
                        'compression_ratio': self.compression_ratio,
                        'method': 'CSV compressed (gzip)'
                    })
                else:
                    results.append({
                        'file': file_path,
                        'status': 'failed',
                        'method': 'CSV compressed (gzip)'
                    })
            
            elif method == 'parquet_replace':
                parquet_path = self.compress_csv_to_parquet_replace(file_path, backup_original)
                if parquet_path:
                    results.append({
                        'file': file_path,
                        'new_file': parquet_path,
                        'status': 'success',
                        'original_size_mb': self.original_size_mb,
                        'compressed_size_mb': self.compressed_size_mb,
                        'compression_ratio': self.compression_ratio,
                        'method': 'Replaced with Parquet'
                    })
                else:
                    results.append({
                        'file': file_path,
                        'status': 'failed',
                        'method': 'Replaced with Parquet'
                    })
            
            print("="*50)
        
        # Tá»•ng káº¿t
        if results:
            print("\nğŸ“Š Tá»”NG Káº¾T NÃ‰N NGAY Táº I CHá»–")
            print("="*50)
            
            successful = [r for r in results if r['status'] == 'success']
            failed = [r for r in results if r['status'] == 'failed']
            
            print(f"ğŸ“ Tá»•ng sá»‘ file: {len(results)}")
            print(f"âœ… ThÃ nh cÃ´ng: {len(successful)}")
            print(f"âŒ Tháº¥t báº¡i: {len(failed)}")
            
            if successful:
                total_original = sum(r['original_size_mb'] for r in successful)
                total_compressed = sum(r['compressed_size_mb'] for r in successful)
                avg_ratio = sum(r['compression_ratio'] for r in successful) / len(successful)
                
                print(f"\nğŸ“Š Tá»•ng kÃ­ch thÆ°á»›c gá»‘c: {total_original:.2f} MB")
                print(f"ğŸ“Š Tá»•ng kÃ­ch thÆ°á»›c sau nÃ©n: {total_compressed:.2f} MB")
                print(f"ğŸ¯ Tiáº¿t kiá»‡m tá»•ng: {total_original - total_compressed:.2f} MB")
                print(f"ğŸ“ˆ Tá»· lá»‡ nÃ©n trung bÃ¬nh: {avg_ratio:.1f}%")
            
            # LÆ°u bÃ¡o cÃ¡o
            report_df = pd.DataFrame(results)
            report_path = 'compression_in_place_report.csv'
            report_df.to_csv(report_path, index=False)
            print(f"\nğŸ“„ BÃ¡o cÃ¡o Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: {report_path}")
        
        return results

def get_system_info():
    """Láº¥y thÃ´ng tin há»‡ thá»‘ng"""
    print("ğŸ’» THÃ”NG TIN Há»† THá»NG")
    print("="*50)
    print(f"CPU: {psutil.cpu_count()} cores")
    print(f"RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB")
    print(f"RAM Available: {psutil.virtual_memory().available / (1024**3):.1f} GB")
    print("="*50)

def main():
    """HÃ m chÃ­nh"""
    print("="*50)
    print("     CSV FILE COMPRESSOR - IN-PLACE")
    print("     NÃ©n CSV NGAY Táº I CHá»– (giáº£m kÃ­ch thÆ°á»›c file)")
    print("="*50)
    
    # Hiá»ƒn thá»‹ thÃ´ng tin há»‡ thá»‘ng
    get_system_info()
    
    # Táº¡o compressor
    compressor = CSVCompressor(target_size_mb=25)
    
    # DANH SÃCH FILE Cáº¦N NÃ‰N - THAY THáº¾ NGAY Táº I CHá»–
    files_input = ('/app/data/application_train.csv', '/app/data/df_processed.csv')
    file_paths = list(files_input)
    
    # Kiá»ƒm tra file tá»“n táº¡i
    valid_files = []
    for file_path in file_paths:
        if os.path.exists(file_path):
            valid_files.append(file_path)
            size_mb = os.path.getsize(file_path) / (1024**2)
            print(f"âœ… TÃ¬m tháº¥y: {file_path} ({size_mb:.1f} MB)")
        else:
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y: {file_path}")
    
    if not valid_files:
        print("âŒ KhÃ´ng cÃ³ file nÃ o Ä‘á»ƒ nÃ©n!")
        exit(1)
    
    print(f"\nğŸ“ Sáº½ nÃ©n NGAY Táº I CHá»– {len(valid_files)} file:")
    for f in valid_files:
        size_mb = os.path.getsize(f) / (1024**2)
        print(f"   â€¢ {Path(f).name} ({size_mb:.1f} MB)")
    
    # Há»i phÆ°Æ¡ng phÃ¡p nÃ©n
    print("\nğŸ“‚ PHÆ¯Æ NG PHÃP NÃ‰N:")
    print("1. Giá»¯ nguyÃªn Ä‘á»‹nh dáº¡ng CSV (nÃ©n gzip) - váº«n lÃ  file .csv")
    print("2. Äá»•i sang Parquet (.csv â†’ .parquet) - nÃ©n tá»‘t hÆ¡n")
    print("3. Táº¡o file má»›i, giá»¯ nguyÃªn file gá»‘c")
    
    method_choice = input("\nğŸ‘‰ Chá»n phÆ°Æ¡ng phÃ¡p (1-3): ").strip()
    
    # Thá»±c hiá»‡n nÃ©n
    if method_choice == '1':
        print("\nğŸš€ Äang nÃ©n CSV NGAY Táº I CHá»– (giá»¯ Ä‘á»‹nh dáº¡ng CSV)...")
        results = compressor.compress_multiple_files_in_place(
            valid_files, 
            method='csv_compressed',
            backup_original=True
        )
    elif method_choice == '2':
        print("\nğŸš€ Äang thay tháº¿ CSV báº±ng Parquet...")
        results = compressor.compress_multiple_files_in_place(
            valid_files,
            method='parquet_replace',
            backup_original=True
        )
    elif method_choice == '3':
        print("\nğŸš€ Äang nÃ©n vÃ  táº¡o file má»›i...")
        # Gá»i phÆ°Æ¡ng thá»©c cÅ© Ä‘á»ƒ táº¡o file má»›i
        results = compressor.compress_multiple_files(valid_files, 'parquet')
    else:
        print("âš ï¸  Lá»±a chá»n khÃ´ng há»£p lá»‡, máº·c Ä‘á»‹nh nÃ©n CSV táº¡i chá»—")
        results = compressor.compress_multiple_files_in_place(
            valid_files,
            method='csv_compressed',
            backup_original=True
        )
    
    # Kiá»ƒm tra káº¿t quáº£ cuá»‘i cÃ¹ng
    print("\nğŸ” KIá»‚M TRA Káº¾T QUáº¢:")
    print("="*50)
    
    for file_path in valid_files:
        if os.path.exists(file_path):
            size_mb = os.path.getsize(file_path) / (1024**2)
            print(f"âœ… {Path(file_path).name}: {size_mb:.2f} MB")
        else:
            # CÃ³ thá»ƒ file Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»•i thÃ nh .parquet
            parquet_path = str(Path(file_path).with_suffix('.parquet'))
            if os.path.exists(parquet_path):
                size_mb = os.path.getsize(parquet_path) / (1024**2)
                print(f"âœ… {Path(parquet_path).name}: {size_mb:.2f} MB (Ä‘Ã£ Ä‘á»•i tá»« CSV)")
            else:
                print(f"âŒ File khÃ´ng tá»“n táº¡i: {file_path}")
    
    print("\nâœ¨ HoÃ n táº¥t!")

if __name__ == "__main__":
    main()